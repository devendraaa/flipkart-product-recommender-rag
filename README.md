# ðŸ›’ Flipkart Product Recommender (RAG-based AI System)

> An **end-to-end Retrieval-Augmented Generation (RAG)** product recommendation system for Flipkart-style e-commerce data, built with **LangChain, Groq LLM, and AstraDB**, and deployed using **Docker & Kubernetes** with **production-grade monitoring**.

---

## ðŸš€ Problem Statement

E-commerce platforms host millions of products and reviews.  
Traditional keyword-based search often fails to deliver:

- Context-aware results  
- Personalized recommendations  
- Conversational search experience  

This project solves that problem using **RAG + LLMs**.

---

## ðŸ§  Solution Overview

The system combines **vector-based retrieval** with **LLM reasoning** to generate intelligent product recommendations.

### High-level Flow:
1. User submits a query  
2. Query is rewritten using a **history-aware retriever**  
3. Relevant product data is fetched from **AstraDB Vector Store**  
4. Retrieved context is injected into **Groq LLM**  
5. LLM generates concise, creative, and grounded responses  

---


## ðŸ—ï¸ Architecture

User
â†“
Flask Web UI
â†“
LangChain RAG Pipeline
â”œâ”€â”€ Query Rephraser (History-aware)
â”œâ”€â”€ AstraDB Vector Store
â”œâ”€â”€ Context Retrieval
â””â”€â”€ Groq LLM (Response Generation)
â†“
Dockerized Application
â†“
Kubernetes (GCP / Minikube)
â†“
Prometheus (Monitoring & Metrics)


---

## ðŸ› ï¸ Tech Stack

### AI / LLM
- **Groq LLM** â€“ ultra-fast inference  
- **LangChain** â€“ RAG orchestration  
- **HuggingFace Embeddings**

### Data & Retrieval
- **AstraDB Vector Store**
- **History-aware retriever**

### Backend & Deployment
- **Flask**
- **Docker**
- **Kubernetes (Minikube / GCP)**
- **kubectl**

### Observability
- **Prometheus** â€“ application monitoring

---

## âœ¨ Key Features

- ðŸ” RAG-based product recommendations  
- ðŸ§  History-aware conversational retrieval  
- âœï¸ Creative, LLM-generated product summaries  
- âš¡ Low-latency inference using Groq  
- ðŸ³ Fully containerized with Docker  
- â˜¸ï¸ Scalable Kubernetes deployment  
- ðŸ“Š Production-grade monitoring  

---

## ðŸ“Œ Example Use Cases

- â€œBest Bluetooth headphones under â‚¹3000â€  
- â€œCompare these with Sony modelsâ€  
- â€œWhich one has better battery life?â€  
- â€œIs it good for gaming?â€  

âž¡ The system **remembers conversation context** for follow-up queries.

---

## ðŸ“ˆ Production Readiness

Designed with real-world deployment in mind:

- Stateless containers  
- Scalable vector retrieval  
- Kubernetes orchestration  
- Observability-first approach  
- Clean separation of RAG components  

---

## ðŸ§  What I Learned

- Designing **real-world RAG pipelines**  
- Building **history-aware conversational AI**  
- Integrating **LLMs with vector databases**  
- Deploying AI systems on **Docker & Kubernetes**  
- Monitoring AI workloads using **Prometheus**  
- Debugging real production issues  

---

## ðŸ”® Future Improvements

- Real-time data ingestion (APIs / scraping)  
- RAG evaluation (RAGAS)  
- Grafana dashboards  
- Improved UI/UX  
- Multi-model routing  

---

## ðŸ‘¤ Author

**Devendra Umesh Chavan**  
**AI Engineer**  
Founder â€“ *Saavo Avinya Pvt Ltd*

---

## â­ Why This Project Matters

This project demonstrates:

- LLM engineering  
- RAG system design  
- Cloud-native deployment  
- Production observability  
- End-to-end AI system thinking  

> *A realistic example of how modern AI applications are built and deployed in industry.*


